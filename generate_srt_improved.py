#!/usr/bin/env python3
"""
ã‚«ãƒƒãƒˆèª¿æ•´æ¸ˆã¿å‹•ç”»ã‹ã‚‰SRTå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šæ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å®Ÿç¾

Usage:
    python generate_srt_improved.py <video_path> [options]
"""

import argparse
import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.audio_extractor import AudioExtractor
from utils.transcriber_improved import ImprovedTranscriber
from utils.caption_formatter_improved import ImprovedCaptionFormatter
from config import OPENAI_API_KEY, WHISPER_API_ENDPOINT, WHISPER_MODEL, GPT_API_ENDPOINT, GPT_MODEL


def generate_srt_from_captions(captions, output_path):
    """
    ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    
    Args:
        captions: ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆformat_captionsã®å‡ºåŠ›ï¼‰
        output_path: å‡ºåŠ›SRTãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, caption in enumerate(captions['captions'], 1):
            # SRTå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰
            start_time = format_srt_time(caption['start'])
            end_time = format_srt_time(caption['end'])
            
            # SRTãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ›¸ãè¾¼ã¿
            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{caption['text']}\n")
            f.write("\n")
    
    print(f"âœ… SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")


def format_srt_time(seconds):
    """
    ç§’æ•°ã‚’SRTã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰å½¢å¼ã«å¤‰æ›
    ä¾‹: 1.5 -> "00:00:01,500"
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def main():
    parser = argparse.ArgumentParser(
        description='ã‚«ãƒƒãƒˆèª¿æ•´æ¸ˆã¿å‹•ç”»ã‹ã‚‰SRTå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰'
    )
    parser.add_argument('video_path', help='å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›SRTãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--max-chars-per-line', type=int, default=20,
                       help='1è¡Œã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰')
    parser.add_argument('--temp-dir', default='temp',
                       help='ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: tempï¼‰')
    parser.add_argument('--api-key', help='OpenAI APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‚ˆã‚Šå„ªå…ˆï¼‰')
    
    args = parser.parse_args()
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    video_path = Path(args.video_path)
    if not video_path.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
        sys.exit(1)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
    if args.output:
        output_path = Path(args.output)
    else:
        output_dir = Path('output')
        output_dir.mkdir(exist_ok=True)
        output_path = output_dir / f"{video_path.stem}_subtitles_improved.srt"
    
    # APIã‚­ãƒ¼ã®è¨­å®š
    api_key = args.api_key or OPENAI_API_KEY
    if not api_key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã™ã‚‹ã‹ã€--api-key ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    temp_dir = Path(args.temp_dir)
    temp_dir.mkdir(exist_ok=True)
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’åˆæœŸåŒ–
    audio_path = temp_dir / f"{video_path.stem}_audio.wav"
    
    try:
        print(f"ğŸ¬ å‹•ç”»ã‚’å‡¦ç†ä¸­: {video_path}")
        print("ğŸš€ æ”¹è‰¯ç‰ˆï¼šå˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½¿ç”¨")
        
        # 1. éŸ³å£°ã‚’æŠ½å‡º
        print("ğŸ”Š éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
        extractor = AudioExtractor()
        audio_path_str = extractor.extract_audio(str(video_path), str(temp_dir))
        audio_path = Path(audio_path_str)
        
        # 2. éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆå˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
        print("ğŸ“ éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­ï¼ˆå˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰...")
        transcriber = ImprovedTranscriber(api_key, WHISPER_API_ENDPOINT, WHISPER_MODEL)
        transcript = transcriber.transcribe(str(audio_path))
        
        if not transcript:
            print("âŒ ã‚¨ãƒ©ãƒ¼: æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        
        # å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ç¢ºèª
        if 'words' in transcript:
            print(f"âœ… å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆ{len(transcript['words'])}å˜èªï¼‰")
        else:
            print("âš ï¸ è­¦å‘Š: å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # 3. ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        print("âœ‚ï¸ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¸­...")
        formatter = ImprovedCaptionFormatter(
            api_key, 
            GPT_API_ENDPOINT, 
            GPT_MODEL,
            max_chars_per_line=args.max_chars_per_line
        )
        formatted_text = formatter.format_captions(transcript['text'])
        
        # æ•´å½¢æ¸ˆã¿ãƒ†ãƒ­ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆå˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ´»ç”¨ï¼‰
        captions_path = temp_dir / f"{video_path.stem}_captions_improved.json"
        captions_data = formatter.save_formatted_captions(
            formatted_text, transcript, str(captions_path)
        )
        
        # 4. SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        print("ğŸ“„ SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
        generate_srt_from_captions(captions_data, output_path)
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        total_captions = len(captions_data['captions'])
        total_duration = captions_data['captions'][-1]['end'] if captions_data['captions'] else 0
        
        print("\nğŸ“Š ç”Ÿæˆçµæœ:")
        print(f"  - ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ•°: {total_captions}")
        print(f"  - ç·æ™‚é–“: {format_srt_time(total_duration).replace(',', '.')}")
        print(f"  - 1è¡Œæœ€å¤§æ–‡å­—æ•°: {args.max_chars_per_line}")
        print(f"  - å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        print(f"  - ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç²¾åº¦: {'é«˜ï¼ˆå˜èªãƒ¬ãƒ™ãƒ«ï¼‰' if 'words' in transcript else 'æ¨™æº–ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ï¼‰'}")
        
        # æœ€åˆã®æ•°è¡Œã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        print("\nğŸ“ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®3ã¤ï¼‰:")
        for i, caption in enumerate(captions_data['captions'][:3], 1):
            print(f"{i}. [{format_srt_time(caption['start'])} - {format_srt_time(caption['end'])}]")
            print(f"   {caption['text']}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if audio_path.exists():
            audio_path.unlink()


if __name__ == "__main__":
    main()