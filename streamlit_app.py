"""
AIå‹•ç”»ã‚«ãƒƒãƒˆï¼†ãƒ†ãƒ­ãƒƒãƒ—ãƒ„ãƒ¼ãƒ« - Streamlit Webç‰ˆ
ãƒãƒ¼ãƒ ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªSRTç”Ÿæˆãƒ„ãƒ¼ãƒ«
"""

import streamlit as st
import tempfile
import os
from pathlib import Path

# ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.audio_extractor import AudioExtractor
from utils.transcriber_improved import ImprovedTranscriber
from utils.caption_formatter_japanese import JapaneseCaptionFormatter

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIå­—å¹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«",
    page_icon="ðŸŽ¬",
    layout="centered"
)

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜Ž
st.title("ðŸŽ¬ AIå­—å¹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«")
st.markdown("""
### å‹•ç”»ã‹ã‚‰é«˜ç²¾åº¦ãªå­—å¹•ï¼ˆSRTï¼‰ã‚’è‡ªå‹•ç”Ÿæˆ
- æ—¥æœ¬èªžç‰¹åŒ–ã®æ–‡å­—ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
- OpenAI Whisper APIã«ã‚ˆã‚‹é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—  
- GPT-4ã«ã‚ˆã‚‹è‡ªç„¶ãªå­—å¹•æ•´å½¢
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIè¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        help="sk-ã§å§‹ã¾ã‚‹APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    st.divider()
    
    st.subheader("ðŸ“ å­—å¹•è¨­å®š")
    max_chars = st.slider(
        "1è¡Œã‚ãŸã‚Šã®æœ€å¤§æ–‡å­—æ•°",
        min_value=10,
        max_value=30,
        value=20,
        step=1
    )
    
    st.divider()
    
    st.info("""
    ðŸ’¡ **ä½¿ã„æ–¹**
    1. OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›
    2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. ã€Œå­—å¹•ã‚’ç”Ÿæˆã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
if not api_key:
    st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
else:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠž",
        type=['mp4', 'mov', 'avi', 'mkv', 'm4v'],
        help="å¯¾å¿œå½¢å¼: MP4, MOV, AVI, MKV, M4V"
    )
    
    if uploaded_file is not None:
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {uploaded_file.name}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{uploaded_file.size / 1024 / 1024:.1f} MB")
        with col2:
            file_ext = uploaded_file.name.split('.')[-1].upper()
            st.metric("ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼", file_ext)
        
        # å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³
        if st.button("ðŸš€ å­—å¹•ã‚’ç”Ÿæˆ", type="primary"):
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
                with tempfile.TemporaryDirectory() as temp_dir:
                    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                    video_path = Path(temp_dir) / uploaded_file.name
                    with open(video_path, 'wb') as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # 1. éŸ³å£°æŠ½å‡º
                    status_text.text("ðŸ”Š éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
                    progress_bar.progress(20)
                    
                    extractor = AudioExtractor()
                    audio_path = extractor.extract_audio(str(video_path), temp_dir)
                    
                    # 2. æ–‡å­—èµ·ã“ã—
                    status_text.text("ðŸ“ éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­...")
                    progress_bar.progress(40)
                    
                    transcriber = ImprovedTranscriber(
                        api_key,
                        "https://api.openai.com/v1/audio/transcriptions",
                        "whisper-1"
                    )
                    transcript = transcriber.transcribe(audio_path)
                    
                    if not transcript:
                        st.error("âŒ æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        st.stop()
                    
                    # å˜èªžæ•°ã‚’è¡¨ç¤º
                    if 'words' in transcript:
                        st.info(f"ðŸ“Š æ–‡å­—ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—: {len(transcript['words'])}æ–‡å­—")
                    
                    # 3. ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ•´å½¢
                    status_text.text("âœ‚ï¸ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆä¸­...")
                    progress_bar.progress(60)
                    
                    formatter = JapaneseCaptionFormatter(
                        api_key,
                        "https://api.openai.com/v1/chat/completions",
                        "gpt-4o",
                        max_chars_per_line=max_chars
                    )
                    formatted_text = formatter.format_captions(transcript['text'])
                    
                    # 4. SRTç”Ÿæˆ
                    status_text.text("ðŸ“„ SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
                    progress_bar.progress(80)
                    
                    captions_data = formatter.save_formatted_captions(
                        formatted_text,
                        transcript,
                        str(Path(temp_dir) / "captions.json")
                    )
                    
                    # SRTãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                    srt_content = generate_srt_content(captions_data)
                    
                    # å®Œäº†
                    progress_bar.progress(100)
                    status_text.text("âœ… å­—å¹•ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                    # çµæžœè¡¨ç¤º
                    st.success(f"ðŸŽ‰ å­—å¹•ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                    
                    # çµ±è¨ˆæƒ…å ±
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ•°", len(captions_data['captions']))
                    with col2:
                        total_duration = captions_data['captions'][-1]['end'] if captions_data['captions'] else 0
                        st.metric("ç·æ™‚é–“", format_time(total_duration))
                    with col3:
                        st.metric("ç²¾åº¦", "é«˜ï¼ˆæ–‡å­—ãƒ¬ãƒ™ãƒ«ï¼‰")
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    with st.expander("ðŸ“ å­—å¹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5ã¤ï¼‰"):
                        for i, caption in enumerate(captions_data['captions'][:5], 1):
                            st.text(f"{i}. [{format_srt_time(caption['start'])} - {format_srt_time(caption['end'])}]")
                            st.text(f"   {caption['text']}\n")
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.download_button(
                        label="ðŸ“¥ SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=srt_content,
                        file_name=f"{Path(uploaded_file.name).stem}_subtitles.srt",
                        mime="text/plain"
                    )
                    
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.exception(e)


def generate_srt_content(captions_data):
    """ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰SRTå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    lines = []
    for i, caption in enumerate(captions_data['captions'], 1):
        lines.append(str(i))
        lines.append(f"{format_srt_time(caption['start'])} --> {format_srt_time(caption['end'])}")
        lines.append(caption['text'])
        lines.append("")  # ç©ºè¡Œ
    
    return "\n".join(lines)


def format_srt_time(seconds):
    """ç§’æ•°ã‚’SRTã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰å½¢å¼ã«å¤‰æ›"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def format_time(seconds):
    """ç§’æ•°ã‚’æ™‚:åˆ†:ç§’å½¢å¼ã«å¤‰æ›"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes}:{secs:02d}"


# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <small>
    AIå‹•ç”»ã‚«ãƒƒãƒˆï¼†ãƒ†ãƒ­ãƒƒãƒ—ãƒ„ãƒ¼ãƒ« v1.0 | 
    Powered by OpenAI Whisper & GPT-4
    </small>
</div>
""", unsafe_allow_html=True)